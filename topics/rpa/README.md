## Table of contents

1. [Papers](#papers)


## Papers 
<!---
 I'm not sure if it should be here. It isn't a paper, but rather paper-alike brochure. On the other hand it may be interesting from business perspective.
--->
* [Intelligent Document Processing Automate Business with Fluid Workflow](https://www.konicaminolta.jp/about/research/technology_report/2021/pdf/18_xu.pdf)
  <details>
  <summary> Ting Xu et al. <em>Konica Minolta Technology Report</em> 2021 </summary>
  </details>

* [Human-Document Interaction Systems -- A New Frontier for Document Image Analysis](http://www.cvc.uab.es/~marcal/pdfs/DAS16b.pdf)
  <details>
  <summary> Dimosthenis Karatzas et al. <em>DAS</em> 2016 </summary>
    All indications show that paper documents will not cede in favour of their digital counterparts, but will instead be used increasingly in conjunction with digital information. An open challenge is how to seamlessly link the physical with the digital -- how to continue taking advantage of the important affordances of paper, without missing out on digital functionality. This paper presents the authors' experience with developing systems for Human-Document Interaction based on augmented document interfaces and examines new challenges and opportunities arising for the document image analysis field in this area. The system presented combines state of the art camera-based document image analysis techniques with a range of complementary technologies to offer fluid Human-Document Interaction. Both fixed and nomadic setups are discussed that have gone through user testing in real-life environments, and use cases are presented that span the spectrum from business to educational applications.
  </details>


Related:
* [Information Extraction from Text Intensive and Visually Rich Banking Documents](https://www.sciencedirect.com/science/article/pii/S0306457320308566)
  <details>
  <summary> Berke Oral et al. <em>Information Processing & Management</em> 2020 </summary>
    Document types, where visual and textual information plays an important role in their analysis and understanding, pose a new and attractive area for information extraction research. Although cheques, invoices, and receipts have been studied in some previous multi-modal studies, banking documents present an unexplored area due to the naturalness of the text they possess in addition to their visual richness. This article presents the first study which uses visual and textual information for deep-learning based information extraction on text-intensive and visually rich scanned documents which are, in this instance, unstructured banking documents, or more precisely, money transfer orders. The impact of using different neural word representations (i.e., FastText, ELMo, and BERT) on IE subtasks (namely, named entity recognition and relation extraction stages), positional features of words on document images and auxiliary learning with some other tasks are investigated. The article proposes a new relation extraction algorithm based on graph factorization to solve the complex relation extraction problem where the relations within documents are n-ary, nested, document-level, and previously indeterminate in quantity. Our experiments revealed that the use of deep learning algorithms yielded around 10 percentage points improvement on the IE sub-tasks. The inclusion of word positional features yielded around 3 percentage points of improvement in some specific information fields. Similarly, our auxiliary learning experiments yielded around 2 percentage points of improvement on some information fields associated with the specific transaction type detected by our auxiliary task. The integration of the information extraction system into a real banking environment reduced cycle times substantially. When compared to the manual workflow, document processing pipeline shortened book-to-book money transfers to 10 minutes (from 29 min.) and electronic fund transfers (EFT) to 17 minutes (from 41 min.) respectively.
  </details>


